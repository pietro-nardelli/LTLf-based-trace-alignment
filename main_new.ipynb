{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "RA_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "da65825a160f90d23b1552c1b09cfcae4ade59ffe0052a72d5f8001054c797a0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LTL-f BASED-TRACE ALIGNMENT"
      ],
      "metadata": {
        "id": "N3zltNFvjHqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From constraint to LTL-f: http://www.diag.uniroma1.it/degiacom/papers/2014/AAAI14.pdf\n",
        "\n",
        "From LTL-f to DFA: http://ltlf2dfa.diag.uniroma1.it/\n",
        "\n",
        "From LTL-f to automaton: https://github.com/whitemech/logaut\n",
        "\n",
        "LTL2DFA library: https://github.com/whitemech/LTLf2DFA/"
      ],
      "metadata": {
        "id": "xUIgFqBdxqkx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import re\n",
        "from typing import Match, cast #, Tuple\n",
        "\n",
        "from ltlf2dfa.parser.ltlf import LTLfParser\n",
        "from logaut.backends.common.process_mona_output import (\n",
        "    parse_automaton,\n",
        "    parse_mona_output,\n",
        ")\n",
        "\n",
        "'''from logaut import ltl2dfa\n",
        "from pylogics.parsers import parse_ltl'''"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from logaut import ltl2dfa\\nfrom pylogics.parsers import parse_ltl'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constraint automaton"
      ],
      "metadata": {
        "id": "UAFM4Xbhje6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONSTRAINTS**\n",
        "\n",
        "- [x] Chain precedence activity 16 - 17\n",
        "- [x] Existence activity 1\n",
        "- [x] Precedence activity 9 -10\n",
        "- [x] Responded existence activity 5 - 6\n",
        "- [x] Chain response activity 14 - 15\n",
        "- [x] Not co-existence activity 19 -20\n",
        "- [x] Not succession activity 20 -21\n",
        "- [x] Not chain succession activity 22 - 23\n",
        "- [x] Response activity 11 - 12\n",
        "- [x] Absence2 activity 2\n"
      ],
      "metadata": {
        "id": "CSQa8IzzAWAH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "def postprocess_output(output: str) -> str:\n",
        "    \"\"\"\n",
        "    Post-process MONA output.\n",
        "    Capture the output related to the MONA DFA transitions.\n",
        "    :param: the raw output from the LTLf2DFA tool.\n",
        "    :return: the output associated to the DFA.\n",
        "    \"\"\"\n",
        "    regex = re.compile(\n",
        "        r\".*(?=\\nFormula is (valid|unsatisfiable)|A counter-example)\",\n",
        "        flags=re.MULTILINE | re.DOTALL,\n",
        "    )\n",
        "    match = regex.search(output)\n",
        "    if match is None:\n",
        "        raise Exception(\"cannot find automaton description in MONA output.\")\n",
        "    return cast(Match, regex.search(output)).group(0)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "parser = LTLfParser()\n",
        "\n",
        "constraint_formulas = {\"existence\":\"F(a)\", \n",
        "                       \"absence2\":\"!(F((b & X(F(b)))))\", \n",
        "                       \"response\":\"G(k -> F(l))\", \n",
        "                       \"precedence\":\"((!(j) U i) | G(!(j)))\",\n",
        "                       \"chain_response\":\"G((n -> X(o)))\", \n",
        "                       \"chain_precedence\": \"(!(q) & G((X(q) -> p)))\",\n",
        "                       \"responded_existence\":\"(F(e) -> F(f))\", \n",
        "                       \"not_coexistence\":\"!((F(s) & F(t)))\", \n",
        "                       \"not_succession\":\"G((t -> !(F(u))))\", \n",
        "                       \"not_chain_succession\":\"G((v <-> !(X(w))))\",\n",
        "                       \"formula_inventata\":\"(F(a) & F(b)) -> G(c)\"}"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "#constraint_formulas = {\"existence\":\"F(a)\",\"response\":\"G(k -> F(l))\"}\n",
        "index = 1\n",
        "\n",
        "all_automata = {}\n",
        "\n",
        "for type_constr,f in constraint_formulas.items():\n",
        "    build_automaton = {}\n",
        "    build_automaton[\"name\"] = type_constr\n",
        "    build_automaton[\"formula\"] = f\n",
        "\n",
        "    all_states_constr = []\n",
        "    final_states_constr = []\n",
        "    init_states_constr = []\n",
        "    rejecting_states_constr = []\n",
        "    rho_constr_basic = []\n",
        "    rho_tobe_negated = []\n",
        "\n",
        "    ## Parser + dfa #####################################################\n",
        "    formula = parser(f)       # returns an LTLfFormula\n",
        "    dfa = formula.to_dfa(mona_dfa_out=True)\n",
        "    mona_output = parse_mona_output(postprocess_output(dfa))\n",
        "    automaton = parse_automaton(mona_output)\n",
        "    #automaton.to_graphviz().render(\"automata/\"+type_constr+\".dfa\", view=True)\n",
        "\n",
        "    ## save all what is needed ##########################################\n",
        "    init_states_constr = 's1'\n",
        "    \n",
        "    states = set.union(mona_output.rejecting_states, mona_output.accepting_states)\n",
        "    states.remove(0)\n",
        "    states = list(states)\n",
        "    for elem in states:\n",
        "        all_states_constr.append('s'+str(elem))\n",
        "\n",
        "    for elem in list(mona_output.accepting_states):\n",
        "        final_states_constr.append('s'+str(elem))\n",
        "\n",
        "    alphabet = mona_output.variable_names\n",
        "\n",
        "    for key,elem in mona_output.transitions.items():\n",
        "        s_start = key\n",
        "        if(s_start != 0):\n",
        "            for k,e in elem.items():\n",
        "                s_end = k\n",
        "                sum = 0\n",
        "                if(s_end != s_start):\n",
        "                    comb = list(e)[0]\n",
        "                    for char in comb:\n",
        "                        if(char!='X'):\n",
        "                            sum += int(char)\n",
        "                    if(sum > 1):\n",
        "                        continue\n",
        "                    elif(sum == 1):\n",
        "                        index1 = comb.find('1')\n",
        "                        rho_constr_basic.append(\"s\"+str(s_start)+\" \"+alphabet[index1]+\" s\"+str(s_end))\n",
        "                    elif(sum == 0):\n",
        "                        ## SBAGLIATO !!!!!!!!!!! #########################################\n",
        "                        # vedi output di cella dove gestiamo le trans negate con l'alfabeto di\n",
        "                        # traccia + alf di constr (ci sono trans ripetute)\n",
        "                        indeces0 = [i for i in range(len(comb)) if comb[i] in '0']\n",
        "                        res_list = [alphabet[i] for i in indeces0]\n",
        "                        rho_tobe_negated.append([s_start,s_end,res_list])\n",
        "\n",
        "\n",
        "    build_automaton[\"all_states\"] = all_states_constr\n",
        "    build_automaton[\"final_states\"] = final_states_constr\n",
        "    build_automaton[\"init_state\"] = init_states_constr\n",
        "    build_automaton[\"transitions\"] = rho_constr_basic\n",
        "    build_automaton[\"symbols_constr\"] = alphabet\n",
        "    build_automaton[\"negated_transitions\"] = rho_tobe_negated\n",
        "\n",
        "    all_automata[\"a\"+str(index)] = build_automaton\n",
        "\n",
        "    index += 1"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "for i in range(11):\n",
        "    print(all_automata[\"a\"+str(i+1)][\"negated_transitions\"])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[[2, 1, ['P']]]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[[1, 2, ['V']], [3, 2, ['V', 'W']]]\n",
            "[[1, 2, ['A', 'B', 'C']], [4, 3, ['A', 'C']], [6, 5, ['B', 'C']], [8, 7, ['C']]]\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load xes file\n",
        "containing the trace"
      ],
      "metadata": {
        "id": "I8Qh6gkJjR6R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "log_path = \"dataset/logs/synthetic-logs/10constraints/1-constraint-inverted/log-from-10constr-model-1constr_inverted-1-50.xes\""
      ],
      "outputs": [],
      "metadata": {
        "id": "Otc3Rvi-2wXS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "voc = {}\n",
        "for i in range(len(alphabet)):\n",
        "    voc[i+1] = alphabet[i]\n",
        "\n",
        "def convertNumberToChar (val):\n",
        "    return voc[val]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "# Legge dal file .xes, estrapola le tracce, trasforma il valore delle tracce in caratteri,\n",
        "# infine aggiungile al log sottoforma di stringhe\n",
        "def readLog (log_path):\n",
        "    # Inizializzazione variabili\n",
        "    flag = False;           # Indica quando dobbiamo leggere un evento dal file\n",
        "    trace = [];             # Lista di eventi sottoforma di interi\n",
        "    traceChar = [];         # Lista di eventi sottoforma di char\n",
        "    traceString = \"\";       # Stringa composta da eventi sottoforma di char\n",
        "    log = []               # Lista di tracce ognuna delle quali è una stringa di char\n",
        "\n",
        "    # Apriamo il file e leggiamolo riga per riga\n",
        "    f = open  (log_path)\n",
        "    f1 = f.readlines()\n",
        "    \n",
        "    # Per ogni riga del file...\n",
        "    for x in f1:\n",
        "        # Se c'è un evento, attiviamo la flag\n",
        "        if (x.__contains__(\"<event>\")):\n",
        "            flag = True\n",
        "        # Se flag attiva e siamo sulla riga dove è presente il nome dell'evento,\n",
        "        # estrapoliamo il nome dell'evento e appendiamolo a trace\n",
        "        if (flag and x.__contains__('<string key=\"concept:name\"')):\n",
        "            val = x.split('value=\"activity ',1)[1]\n",
        "            val = val.split('\"')[0]                \n",
        "            trace.append(val)\n",
        "            flag = False\n",
        "        # Quando non ci sono più eventi possiamo lavorare sulla traccia in questione\n",
        "        if (x.__contains__(\"</trace>\")):\n",
        "            for event in trace:\n",
        "                traceChar.append(convertNumberToChar(int(event)))  # Converti gli eventi in char \n",
        "            traceString = \"\".join(traceChar)                       # Lista di eventi -> stringa\n",
        "            log.append(traceString)                                # Appendi stringa a log\n",
        "\n",
        "            # Inizializza nuovamente le variabili\n",
        "            trace = []\n",
        "            traceChar = []\n",
        "            traceString = \"\"\n",
        "    return log"
      ],
      "outputs": [],
      "metadata": {
        "id": "944iEX333Q2E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "log = readLog(log_path) # list of traces\n",
        "\n",
        "#trace = log[2]\n",
        "#trace = 'stkai'\n",
        "#print (trace)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7ILjAXH3XzJ",
        "outputId": "6ca28027-ffc9-49c6-a083-e798f5350661"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "#traces_log = log\n",
        "traces_log = ['STAI']\n",
        "\n",
        "all_traces = []\n",
        "\n",
        "for t in traces_log:\n",
        "    trace = {}\n",
        "    \n",
        "    symbols_trace = list(set(t))\n",
        "    \n",
        "    ## Build trace automaton ###################################\n",
        "    rho_trace_basic = []\n",
        "    Q_trace = []\n",
        "    for i in range(len(trace)):\n",
        "        Q_trace.append('t'+str(i))\n",
        "        rho_trace_basic.append('t'+str(i)+\" \"+trace[i] +\" \"+ 't'+str(i+1))\n",
        "\n",
        "    Q_trace.append('t'+str(len(trace)))\n",
        "    init_state_trace = Q_trace[0]\n",
        "    final_state_trace = Q_trace[-1]\n",
        "\n",
        "    trace[\"symbols_trace\"] = symbols_trace\n",
        "    trace[\"init_state_trace\"] = init_state_trace\n",
        "    trace[\"final_state_trace\"] = final_state_trace\n",
        "    trace[\"Q_trace\"] = Q_trace\n",
        "    trace[\"rho_trace_basic\"] = rho_trace_basic\n",
        "\n",
        "    all_traces.append(trace)\n",
        "\n",
        "    ## Now we add the transitions for the negated symbols ######\n",
        "\n",
        "    for ID,automaton in all_automata.items():\n",
        "        symb_constr = set(automaton[\"symbols_constr\"])\n",
        "        symb_trace = set(symbols_trace)\n",
        "        all_symbs = list(set.union(symb_constr, symb_trace))\n",
        "        print(all_symbs)\n",
        "\n",
        "        trans1 = automaton[\"transitions\"]\n",
        "        trans = []\n",
        "        for t_neg in automaton[\"negated_transitions\"]:\n",
        "            symbs = all_symbs.copy()\n",
        "            print(t_neg[2])\n",
        "            for t in t_neg[2]:\n",
        "                symbs.remove(t)\n",
        "            print(\"all_symbs after remove: \", symbs)\n",
        "            for elem in symbs:\n",
        "                trans.append(\"s\"+str(t_neg[0])+\" \"+elem+\" s\"+str(t_neg[1]))\n",
        "            print(trans)\n",
        "            print(\"-----------\")\n",
        "\n",
        "        automaton[\"transitions\"] = trans # + trans1\n",
        "    \n",
        "    print(\"___________________________\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'I', 'T', 'S']\n",
            "['I', 'A', 'B', 'T', 'S']\n",
            "['K', 'L', 'A', 'I', 'T', 'S']\n",
            "['J', 'A', 'I', 'T', 'S']\n",
            "['O', 'N', 'A', 'I', 'T', 'S']\n",
            "['Q', 'A', 'I', 'T', 'S', 'P']\n",
            "['P']\n",
            "all_symbs after remove:  ['Q', 'A', 'I', 'T', 'S']\n",
            "['s2 Q s1', 's2 A s1', 's2 I s1', 's2 T s1', 's2 S s1']\n",
            "-----------\n",
            "['A', 'F', 'I', 'T', 'S', 'E']\n",
            "['A', 'I', 'T', 'S']\n",
            "['I', 'A', 'U', 'T', 'S']\n",
            "['T', 'A', 'I', 'W', 'V', 'S']\n",
            "['V']\n",
            "all_symbs after remove:  ['T', 'A', 'I', 'W', 'S']\n",
            "['s1 T s2', 's1 A s2', 's1 I s2', 's1 W s2', 's1 S s2']\n",
            "-----------\n",
            "['V', 'W']\n",
            "all_symbs after remove:  ['T', 'A', 'I', 'S']\n",
            "['s1 T s2', 's1 A s2', 's1 I s2', 's1 W s2', 's1 S s2', 's3 T s2', 's3 A s2', 's3 I s2', 's3 S s2']\n",
            "-----------\n",
            "['I', 'A', 'C', 'B', 'T', 'S']\n",
            "['A', 'B', 'C']\n",
            "all_symbs after remove:  ['I', 'T', 'S']\n",
            "['s1 I s2', 's1 T s2', 's1 S s2']\n",
            "-----------\n",
            "['A', 'C']\n",
            "all_symbs after remove:  ['I', 'B', 'T', 'S']\n",
            "['s1 I s2', 's1 T s2', 's1 S s2', 's4 I s3', 's4 B s3', 's4 T s3', 's4 S s3']\n",
            "-----------\n",
            "['B', 'C']\n",
            "all_symbs after remove:  ['I', 'A', 'T', 'S']\n",
            "['s1 I s2', 's1 T s2', 's1 S s2', 's4 I s3', 's4 B s3', 's4 T s3', 's4 S s3', 's6 I s5', 's6 A s5', 's6 T s5', 's6 S s5']\n",
            "-----------\n",
            "['C']\n",
            "all_symbs after remove:  ['I', 'A', 'B', 'T', 'S']\n",
            "['s1 I s2', 's1 T s2', 's1 S s2', 's4 I s3', 's4 B s3', 's4 T s3', 's4 S s3', 's6 I s5', 's6 A s5', 's6 T s5', 's6 S s5', 's8 I s7', 's8 A s7', 's8 B s7', 's8 T s7', 's8 S s7']\n",
            "-----------\n",
            "___________________________\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trace automaton"
      ],
      "metadata": {
        "id": "a5YU3B8BjWj5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rho_trace_basic = []           # rho = [[q0, w, q1],[q1,k,q2],...,[..,.,qn-1]]\n",
        "Q_trace = []\n",
        "for i in range(len(trace)):\n",
        "    Q_trace.append('t'+str(i))\n",
        "    rho_trace_basic.append('t'+str(i)+\" \"+trace[i] +\" \"+ 't'+str(i+1))\n",
        "\n",
        "Q_trace.append('t'+str(len(trace)))\n",
        "init_state_trace = Q_trace[0]\n",
        "final_state_trace = Q_trace[-1]\n",
        "\n",
        "print(Q_trace)\n",
        "print(rho_trace_basic)"
      ],
      "outputs": [],
      "metadata": {
        "id": "sm0GAMn2apez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f54dcb1-0f20-4436-a99c-cceaf6c5f619"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Planning domain D"
      ],
      "metadata": {
        "id": "uQMiCDBijwF_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "domain_name = \"domain_multi\"\n",
        "problem_name = \"problem_multi\""
      ],
      "outputs": [],
      "metadata": {
        "id": "12YBD3nKhH2Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pddl_domain_initial = \"(define (domain \"+domain_name+\") \"\\\n",
        "                \"(:requirements :strips :typing :action-costs) \"\\\n",
        "                \"(:types trace_state automaton_state - state activity) \"\n",
        "\n",
        "pddl_domain_predicates = \"(:predicates (trace ?t1 - trace_state \"\\\n",
        "                            \"?e - activity \"\\\n",
        "                            \"?t2 - trace_state) \"\\\n",
        "                            \"(automaton ?s1 - automaton_state \"\\\n",
        "                            \"?e - activity \"\\\n",
        "                            \"?s2 - automaton_state) \"\\\n",
        "                            \"(cur_state ?s - state) \"\\\n",
        "                            \"(final_state ?s - state)) \"\n",
        "\n",
        "\n",
        "pddl_domain_actions =  \"(:action sync \"\\\n",
        "                        \":parameters (?t1 - trace_state ?e - activity ?t2 - trace_state) \"\\\n",
        "                        \":precondition (and (cur_state ?t1) (trace ?t1 ?e ?t2)) \"\\\n",
        "                        \":effect(and (not (cur_state ?t1)) (cur_state ?t2) \"\\\n",
        "                        \"(forall (?s1 ?s2 - automaton_state) \"\\\n",
        "                        \"(when (and (cur_state ?s1) \"\\\n",
        "                        \"(automaton ?s1 ?e ?s2)) \"\\\n",
        "                        \"(and (not (cur_state ?s1)) \"\\\n",
        "                        \"(cur_state ?s2)))))) \"\\\n",
        "                        \"(:action add \"\\\n",
        "                        \":parameters (?e - activity) \"\\\n",
        "                        \":effect (and (increase (total-cost) 1) \"\\\n",
        "                        \"(forall (?s1 ?s2 - automaton_state) \"\\\n",
        "                        \"(when (and (cur_state ?s1) \"\\\n",
        "                        \"(automaton ?s1 ?e ?s2)) \"\\\n",
        "                        \"(and (not (cur_state ?s1)) \"\\\n",
        "                        \"(cur_state ?s2)))))) \"\\\n",
        "                        \"(:action del \"\\\n",
        "                        \":parameters (?t1 - trace_state ?e - activity \"\\\n",
        "                        \"?t2 - trace_state) \"\\\n",
        "                        \":precondition (and (cur_state ?t1) (trace ?t1 ?e ?t2)) \"\\\n",
        "                        \":effect (and (increase (total-cost) 1) \"\\\n",
        "                        \"(not (cur_state ?t1)) (cur_state ?t2))))\"\n",
        "\n",
        "pddl_domain = pddl_domain_initial + pddl_domain_predicates + pddl_domain_actions\n",
        "\n",
        "print (pddl_domain)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq0E10UEQ2KN",
        "outputId": "625d168f-b794-402f-dfc3-6944fe96a730"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PDDL problem"
      ],
      "metadata": {
        "id": "Gwp1E1FgpgDQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "symbols = symbols_constr.copy()\n",
        "'''print (Q_trace)\n",
        "print (all_states_constr)\n",
        "print (symbols)\n",
        "print (rho_trace_basic)\n",
        "print (rho_constr_basic)'''"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ztj2xof8Xn8o",
        "outputId": "61cd1c81-4d42-49ec-d01c-d432e7824171"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#type_constraints = ['existence', 'absence2', 'response', 'precedence', 'chain_response','responded_existence', 'chain_precedence', 'not_coexistence', 'not_succession', 'not_chain_succession']\n",
        "type_constraints = [\"existence\",\"response\"]\n",
        "\n",
        "pddl_problem_initial = \"(define (problem \"+problem_name+\") (:domain \"+domain_name+\") \"\n",
        "pddl_problem_objects = \"(:objects \"\n",
        "\n",
        "for q in Q_trace:\n",
        "    pddl_problem_objects += q+\" \"\n",
        "pddl_problem_objects += \"- trace_state \"\n",
        "\n",
        "for type_constr in type_constraints:\n",
        "    for q in all_states_constr[type_constr]:\n",
        "        pddl_problem_objects += q+\" \"\n",
        "    pddl_problem_objects += \"- automaton_state \"\n",
        "\n",
        "for s in symbols:\n",
        "    pddl_problem_objects += s+\" \"\n",
        "pddl_problem_objects += \"- activity\"\n",
        "\n",
        "pddl_problem_objects += \") \"\n",
        "\n",
        "\n",
        "pddl_problem_init = \"(:init (= (total-cost) 0) (cur_state \"+init_state_trace+\") \"\n",
        "for trace in rho_trace_basic:\n",
        "    pddl_problem_init += \"(trace \"+trace+\") \"\n",
        "pddl_problem_init += \"(final_state \"+final_state_trace+\") \"\n",
        "\n",
        "for type_constr in type_constraints:\n",
        "    pddl_problem_init += \"(cur_state \"+init_states_constr[type_constr]+\") \" \n",
        "    for trace in rho_constr_basic[type_constr]:\n",
        "        pddl_problem_init += \"(automaton \"+trace+\") \"\n",
        "\n",
        "    for i in range(len(final_states_constr[type_constr])):\n",
        "        pddl_problem_init += \"(final_state \"+final_states_constr[type_constr][i]+\") \"\n",
        "pddl_problem_init += \") \"\n",
        "\n",
        "\n",
        "pddl_problem_goal = \"(:goal (forall (?s - state) \"\\\n",
        "                    \"(imply (cur_state ?s) (final_state ?s)))) \"\n",
        "pddl_problem_metric = \"(:metric minimize (total-cost)))\"\n",
        "pddl_problem = pddl_problem_initial + pddl_problem_objects + pddl_problem_init + pddl_problem_goal + pddl_problem_metric\n",
        "print (pddl_problem)"
      ],
      "outputs": [],
      "metadata": {
        "id": "lTG7BH12iLmK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63a819f9-6cf3-4c67-f077-fff54aea700c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save .pddl files"
      ],
      "metadata": {
        "id": "uHrzmm9kfKcO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "file1 = open(\"PDDL/\"+domain_name+\".pddl\", \"w\")\n",
        "file1.write(pddl_domain)\n",
        "file1.close()\n",
        "\n",
        "file2 = open(\"PDDL/\"+problem_name+\".pddl\", \"w\")\n",
        "file2.write(pddl_problem)\n",
        "file2.close()"
      ],
      "outputs": [],
      "metadata": {
        "id": "NTBIHF3dfMMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fast-downward planner:\n",
        "`./fast-downward.py domain_multi.pddl problem_multi.pddl --search \"astar(blind())\"`"
      ],
      "metadata": {}
    }
  ]
}